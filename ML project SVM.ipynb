{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries to be used:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_df = pd.read_csv('games.csv')\n",
    "lol_df2 = lol_df[['gameDuration', 'winner','firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald', 't1_towerKills', 't1_inhibitorKills', 't1_baronKills', 't1_dragonKills', 't1_riftHeraldKills', 't2_towerKills', 't2_inhibitorKills', 't2_baronKills', 't2_dragonKills', 't2_riftHeraldKills']]\n",
    "lol_X = lol_df2[['gameDuration', 'firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald', 't1_towerKills', 't1_inhibitorKills', 't1_baronKills', 't1_dragonKills', 't1_riftHeraldKills', 't2_towerKills', 't2_inhibitorKills', 't2_baronKills', 't2_dragonKills', 't2_riftHeraldKills']]\n",
    "lol_X = np.array(lol_X)\n",
    "lol_Y = lol_df2[['winner']]\n",
    "lol_Y = np.array(lol_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_X_scale = preprocessing.scale(lol_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(lol_X_scale, lol_Y, test_size = 0.25, train_size = 0.75, random_state = 42)\n",
    "y_2d_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_2d_test = y_test.reshape(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_svm_linear = []\n",
    "acc_test_svm_linear = []\n",
    "c_svm_linear = []\n",
    "cVals = [0.0001, 0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Complete the function below:\n",
    "# In this function and next 2 functions, we are not passing the data matrices as parameters \n",
    "# because we can use global variables inside the functions.\n",
    "def svm_linear(c):\n",
    "    # TODO - Create an object of svm.SVC(probability = False, kernel = 'linear', C = c) - 5 points\n",
    "    svc_linear = svm.SVC(probability = False, kernel = 'linear', C=c)\n",
    "    \n",
    "    # TODO - Fit the classifier on the training set - 5 points\n",
    "    svc_linear.fit(X_train, y_2d_train)\n",
    "    \n",
    "    # TODO - Find the prediction and accuracy on the training set - 5 points\n",
    "    Yhat_svc_linear_train = svc_linear.predict(X_train)\n",
    "    acc_train = svc_linear.score(X_train, y_2d_train)\n",
    "    \n",
    "    # Adding testing accuracy to acc_train_svm\n",
    "    acc_train_svm_linear.append(acc_train)\n",
    "    print('Train Accuracy = {0:f}'.format(acc_train))\n",
    "    \n",
    "    # TODO - Find the prediction and accuracy on the test set - 5 points\n",
    "    Yhat_svc_linear_test = svc_linear.predict(X_test)\n",
    "    acc_test = svc_linear.score(X_test, y_2d_test)\n",
    "    \n",
    "    # Adding testing accuracy to acc_test_svm\n",
    "    acc_test_svm_linear.append(acc_test)\n",
    "    print('Test Accuracy = {0:f}'.format(acc_test))\n",
    "    \n",
    "    # Appending value of c for graphing purposes\n",
    "    c_svm_linear.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkjay\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Call the above function i.e. svm_linear with different values of parameter 'c'.\n",
    "# Start with smaller values of 'c' say 0.0001, 0.001, 0.01, 0.1, 1, 10, 100\n",
    "for c in cVals:\n",
    "    svm_linear(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write code to plot 2 plots - 10 points\n",
    "# Plot training accuracy(Y-axis) v/s 'c' on X - Axis.\n",
    "# Plot test accuracy(Y-Axis) v/s 'c' on X - Axis.\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(c_svm_linear, acc_train_svm_linear, '-o')\n",
    "plt.plot(c_svm_linear, acc_test_svm_linear, '-o')\n",
    "plt.xscale('log')\n",
    "plt.title(\"SVM Linear Kernel Accuracy vs c\")\n",
    "# Use the following function to have a legend\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'], loc='lower right')\n",
    "plt.grid()\n",
    "plt.show(block=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
